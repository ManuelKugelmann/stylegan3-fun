{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "StyleGAN3"
      ],
      "metadata": {
        "id": "Ah3ZX4A_qAaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Check GPU type\n",
        "#@markdown Factory reset runtime if you don't have the desired GPU.\n",
        "#@markdown - V100 = Excellent (*Available only for Colab Pro users*)\n",
        "#@markdown - P100 = Very Good\n",
        "#@markdown - T4 = Good (*preferred*)\n",
        "#@markdown - K80 = Meh\n",
        "#@markdown - P4 = (*Not Recommended*)\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "67Ng3XNMqFfC",
        "cellView": "form",
        "outputId": "31f6daed-98a3-409a-f513-434153f6bf02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-3b654fde-091d-c5ea-7ab6-8f23c380e760)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.device('cuda:0'))\n",
        "\n",
        "#!pip install --upgrade torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install --upgrade torch==1.10.0+cu111 torchvision==0.11.2+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n"
      ],
      "metadata": {
        "id": "cegSXJKbNsEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import clip\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from IPython.display import display\n",
        "from einops import rearrange\n",
        "from google.colab import files, drive\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "OjaYmYbVH8FF",
        "outputId": "48ab0bb0-8e1e-4f67-896b-764be5d69137"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.1+cu111\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x56504c030000 @  0x7f3c8f7391e7 0x56504871ff98 0x5650486eae27 0x565048869115 0x565048803888 0x5650486ee6f2 0x5650487ccc6e 0x5650486ee349 0x5650487dfe1d 0x565048761e99 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x5650cb6d0000 @  0x7f3c8f7391e7 0x56504871ff98 0x5650486eae27 0x565048801227 0x5650486ee46c 0x5650487dfe1d 0x565048761e99 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486efbda 0x56504875e737 0x5650486efafa\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x56514ad70000 @  0x7f3c8f7391e7 0x565048721008 0x5650487db82e 0x5650486ee2ed 0x5650487dfe1d 0x565048761e99 0x5650486efafa 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875e737 0x5650486efafa 0x56504875d915 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875cced 0x5650486f048c\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x5651ca410000 @  0x7f3c8f7391e7 0x56504871ff98 0x5650487dc21c 0x5650487d6409 0x56504875de7a 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875e737 0x5650486efafa 0x56504875d915 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x56524a372000 @  0x7f3c8f7391e7 0x56504871ff98 0x5650486eae27 0x565048800f2a 0x5650486eda6f 0x56504872e045 0x5650486eec52 0x565048761c25 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875e737 0x5650486efafa 0x56504875d915 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee\n",
            "tcmalloc: large alloc 2137653248 bytes == 0x56524a372000 @  0x7f3c8f7391e7 0x56504871ff98 0x5650486eae27 0x565048869115 0x565048803888 0x5650486ee6f2 0x5650487ccc6e 0x5650486ee349 0x5650487dfe1d 0x565048761e99 0x5650486efafa 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875cced 0x5650486f048c 0x5650486f0698 0x56504875efe4 0x56504875c9ee\n",
            "tcmalloc: large alloc 2672066560 bytes == 0x56504c030000 @  0x7f3c8f73a615 0x5650486eb4cc 0x5650487cb47a 0x5650486ee2ed 0x5650487dfe1d 0x565048761e99 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x5650486efafa 0x56504875dc0d 0x56504875c9ee 0x5650486efbda 0x56504875e737 0x56504875c9ee 0x5650486efbda 0x56504875dc0d 0x56504875cced 0x5650486efbda\n",
            "  Using cached https://download.pytorch.org/whl/cu111/torch-1.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.7 MB)\n",
            "Collecting torchvision==0.11.2+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.2%2Bcu111-cp37-cp37m-linux_x86_64.whl (24.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.5 MB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (1.19.5)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a551ee931427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clip'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = 'stylegan3'\n",
        "GDRIVE_MOUNT = '/content/drive'\n",
        "BASE_DIR = f'{GDRIVE_MOUNT}/MyDrive/colab/'\n",
        "CODE_DIR = f'{BASE_DIR}{NAME}/'"
      ],
      "metadata": {
        "id": "5HE3zQmz5-5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect Google Drive\n",
        "drive.mount(GDRIVE_MOUNT)"
      ],
      "metadata": {
        "id": "hS0paOdq573w",
        "outputId": "b5fef4c4-cf88-4998-a263-d185b58fa0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isdir(CODE_DIR):\n",
        "    %cd {CODE_DIR}\n",
        "    !git pull\n",
        "else:\n",
        "    !git clone https://github.com/ManuelKugelmann/stylegan3-fun.git {CODE_DIR}\n",
        "    %cd {CODE_DIR}"
      ],
      "metadata": {
        "id": "wa_97Pyj57-B",
        "outputId": "e821db6f-0b34-4a9c-8b45-926e018b36a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab/stylegan3\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate an image\n",
        "#@markdown StyleGAN3 pre-trained models for config T (translation equiv.) and config R (translation and rotation equiv.)\n",
        "seed = 4011 #@param {type:\"slider\", min:0, max:9999, step:1}\n",
        "\n",
        "baselink ='https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/'\n",
        "model = \"stylegan3-r-afhqv2-512x512.pkl\" #@param [\"stylegan3-r-afhqv2-512x512.pkl\", \"stylegan3-r-ffhq-1024x1024.pkl\", \"stylegan3-r-ffhqu-1024x1024.pkl\",\"stylegan3-r-ffhqu-256x256.pkl\",\"stylegan3-r-metfaces-1024x1024.pkl\",\"stylegan3-r-metfacesu-1024x1024.pkl\",\"stylegan3-t-afhqv2-512x512.pkl\",\"stylegan3-t-ffhq-1024x1024.pkl\",\"stylegan3-t-ffhqu-1024x1024.pkl\",\"stylegan3-t-ffhqu-256x256.pkl\",\"stylegan3-t-metfaces-1024x1024.pkl\",\"stylegan3-t-metfacesu-1024x1024.pkl\"]\n",
        "\n",
        "# Generate an image using pre-trained model \n",
        "!python gen_images.py --outdir=out --trunc=1 \\\n",
        " --seeds=$seed --network=$baselink$model\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "img = Image.open('/content/stylegan3/out/seed%04d.png' % seed);\n",
        "plt.imshow(img);\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "td8mVoraLNIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Model selection** ðŸŽ­\n",
        "#@markdown - FFHQ: Trained with human faces.\n",
        "#@markdown - MetFaces: Trained with paintings/portraits of human faces.\n",
        "#@markdown - AFHQv2: Trained with animal faces.\n",
        "#@markdown - Cosplay: Trained by [l4rz](https://twitter.com/l4rz) with cosplayer's faces.\n",
        "#@markdown - Wikiart: Trained by [Justin Pinkney](https://www.justinpinkney.com/) with the Wikiart 1024 dataset.\n",
        "#@markdown - Landscapes: Trained by [Justin Pinkney](https://www.justinpinkney.com/) with the LHQ dataset.\n",
        "\n",
        "#@markdown **Run this cell again if you change the model**.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "base_url = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/\"\n",
        "\n",
        "Model = 'FFHQ' #@param [\"FFHQ\", \"MetFaces\", \"AFHQv2\", \"cosplay\", \"Wikiart\", \"Landscapes\"]\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "model_name = {\n",
        "    \"FFHQ\": base_url + \"stylegan3-t-ffhqu-1024x1024.pkl\",\n",
        "    \"MetFaces\": base_url + \"stylegan3-r-metfacesu-1024x1024.pkl\",\n",
        "    \"AFHQv2\": base_url + \"stylegan3-t-afhqv2-512x512.pkl\",\n",
        "    \"cosplay\": \"https://l4rz.net/cosplayface-snapshot-stylegan3t-008000.pkl\",\n",
        "    \"Wikiart\": \"https://drive.google.com/u/0/open?id=18MOpwTMJsl_Z17q-wQVnaRLCUFZYSNkj\",\n",
        "    \"Landscapes\": \"https://drive.google.com/u/0/open?id=14UGDDOusZ9TMb-pOrF0PAjMGVWLSAii1\"\n",
        "}\n",
        "\n",
        "network_url = model_name[Model]\n",
        "\n",
        "with open(fetch_model(network_url), 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)"
      ],
      "metadata": {
        "id": "yt3SS0dfH50N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}